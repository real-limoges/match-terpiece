{% extends 'layouts/main.html' %}
{% block title %}Home{% endblock %}
{% block content %}

<div class="page-header">
    <h1 align='center'>Transfer Learning Demonstration</h1>
</div>

<b><i>
"If I have seen further, it is by standing on the shoulders of giants."
<br> -- Sir Isaac Newton </i></b>

<h3>What is Transfer Learning?</h3>
<p>Transfer learning takes  
</p>

<h3>Which Pre-Trained Neural Network Was Used?</h3>
<p>
VGG16 (also known as OxfordNet.) VGG16 was the 2014 ILSVR (ImageNet) winner; while there have been recent advances in neural networks, it still performs excellently on its intended purpose and prediction is relatively quick.
</p>
<p>
VGG16, as many past winners of the ImageNet competition, uses convolutional layers to process the data. Convolutional layers serve two purposes in helping classify images.
<br>
<li>
Convolutions help decrease the number of neurons in a network. ImageNet items are 224x224 pixels in 3 color channels. For a fully connected neural network, this would require ~150k parameters for each layer. Subsequently, we would not be able to leverage the full capacity of deep learning with such shallow layers.
</li>
<li>
Convolutions help maintain the structure of the image that is passed through it. This is of particular importance in images.
</li>
</p>
<p>Below I've embedded the VGG16 architecture</p>
<center><img src='static/img/vgg16arch.png' class='img-responsive' /></center>
<h3>What Data Was Used</h3>
<p>I used the Flickr API to generate the links of approximately 55 thousand images that were tagged as "abstract art." Of these, 45 thousand images were publically available, and satisfied the 224x224 pixel requirement.
</p>

<h3>Is There Pattern In The Data?</h3>
<p> Here are some very pretty clusters </p>
<img src='static/img/cluster1.png'>

{% endblock %}
